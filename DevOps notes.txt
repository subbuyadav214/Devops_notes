
cluster-a cluster is set of nodes group to gether  

master node--mange,plan,shedule,monitor nodes 

Node- node is machine that physical are virtual which k8s is installed

k8s doesnt manage data persistance we need to manage backing to the data and replicating the and maanaging 


pod-is wrapper of container (Pod is group of container running in a node)
each and every pod is have its own ip adress 
pod can communicate each other using service discovery and (DNS Resolution)& Load balancing
pods are providing a run time enviroment for application deploy ,for deploying the appplication we need better high avilablity and load balancing
between the application

api-server-- it acts as front end of the k8s in oreder to approch k8s clusters
we need to approach apiserver

etcd-- its a key value data store it will store the clusters complete details 
api server is using for the orchestration  of all operation with in the cluster 
it is using external users to perform the maagement operatin of the cluster 

sheduler --it is responsible for distributing the work are container 
 across multiple node it looks newely creted containers and assigned them to nodes
a sheduler idenfy the rite node to place a container on based on the container resourece requriment  worker node capacity  
its responsible for sheduling the application and containers in the nodes      

controller manager-- The controller are the brain behind the orchestration 
their responsible for noticing  and responding when nodes containers 
end points goes down the controller make descession to bring up new containers in such case
  

etcd--it is keyvalue store it will store information about the cluster

containers-- container are running instancess of images that 
are isolated having their own enviroment
own process(using local host containers can communiucate each otehr with respective port)

Container run time--it is underlying software that is used to run container 
ex- for running docker container in a system we need container run  time installed
we need the software that can run containers docker for support equalt install all the nodes in cluster 
 
kublet--kublet is the agent that runs on the each node the agent is responsible for making sure that 
containers are running on the nodes as expected 
Healthinformation of the worker node and cary out the action request by the master on the worker node
kubelet is a server it runs a eachnode in the cluster it listen the instruction form the api-server
it deploy are destroy the containers nodes as requried
the kube apiserver fetches thr sever periodically status report from the kubelet 
to monitor the status of nodes and conatiners  
kubelet is managing the container in the node        

kublet-- kubecontrol tool is used to deploy and manage the application in k8s cluster to get the cluster information and 
to get the other information about node in the cluster manage other things     

kubectl--To interact with k8s server with the cli it is called api
2types  1)Imperative 2)Declarative 

image-- image is package are templtae just time 
a vm template it is used to create one are more containerS

Name spacess - Is nothing but a virtual cluster with in k8s cluster,its a logical group of k8s rsourcess of some project are team 
purpose (managing the applications managing the deployments of a multiple teams in same k8s clusters) 
default, kube-system (used for Kubernetes components), and kube-public (used for public resources
*default *kube-node-lease *
in this name space we can create Resource quota it means like (How many pods how much memory and cpus used )
@kube system name space api,sheduler and etcd components are placed 

kubedeam--is used to set up the cluster
 
In Kubernetes Which component acts as loadbalancer--->Ingress

service--is responsible for making our pods discoverable (acessible)inside the cluser are exposing out side 
with the help of the service we can acess the pods and applications inside the cluster or outside cluster  
identying the pods and forwording the traffic
service --service is bascically used for the setting a permnent ip adress for the each pod 
evene if pod dies also service and ip adress will remains stay 
pods comunicate eac other by usnig service
service is also called asload balancer 
service is usig for thr comuncation betwent he pods      

#service will idenfy the pods based on the labels and selector  

container network pod network (CNI-container networking impelmentation)managing the ips to the pod allocating the ips to the pod 

labels-- labels are basically key value pairs for ideneficatin its kind about metdata(labels are key value pairs which we can attach any k8s) 
ex-- in one project their are 4 teams is working we need to assign the pods for it so we need to give namimg convension (labels)
labels are key value pairs that are generally attached to the pod it kind of tag it is gaven to one are set of to gether pod
and it will help us diplaying and managing the pod to getr as set insted of indivusally 
ex-- we want creatr 5 containers(replicas)we can give for 5 namespacess and all insted of that we are using labels 
apiversion: v1
kind: pod
metadat:
  name: ngnix-pod
  labels:
    app:guestbook
    tier:frontend
    env: dev
spec:
  replicas:5

 Kubernetes Objects

    pods.
    Namespaces.
    ReplicationController
    DeploymentController
    StatefulSets.
    DaemonSets.
    Services.
    ConfigMaps.

 Kubernetes Components

etcd
scheduler
controller-manager
kubelet
kube-proxy
Container runtime


#assigning the labels that we can know the pod is assign to which team 
(naming convensction is to important in prod enviromet we can get to whih pod is assignt to which team by giving the namespace and labels)
using labels with selectors we are creating pods



pod will have a labels while creating thre labels we can use like 

kubeproxy-it is node agent it is a proxy agent its having ip tables the connection rules 
kubeproxy service is ensures that necessaruy roles place on the worker nodes allow the containers 
on them to reach other 
its responsible for enabling the communication b/w with in the service with in the cluser 
note in order to validate attributers are correct are not use below command
*kubeclt apply -f mavenwebapp.yml --dry-run=client 
if we need to fallwo proper indendation and proper attributes

Helm charts--(Package manager for k8s) Helm is pacakge manager wheare instaed of deploying of all the yml files 
indivuasally we are grouping them and  creating a helm charts we are deploying as helm 
  
notein order to communicate the pods when they are in diffrent name space 
FQDN--fully qualified domain name

k8s node port range is 30000-32767

in order to acess the container $ curl cluster_ip

Why we need end points--We need endpoints as an abstraction layer because the 'service' in kubernetes acts as part of the orchestration to ensure 
distribution of traffic to pods (including only sending traffic to healthy pods).
 For example if a pod dies, a replacement pod will be generated, with a new IP address.17-Oct-2018

Replica set-- if any pod is dies means it will recreate again in a healthy pod 
it ensure that specefic number of pod are running at any time 

completek8s is maianting by the control plane 
control panel is maintain by the kubelet s

master node -- in order to convert the master node as control panel we need to run some commands 
# kube init
it will download the images 

DNS- Domain name system it will convert ipadress it to domain name 

Ingress -- Ingress helps to users acees application using single externally acessable URL 
external service is  a service that opens the communication from the external sourcess for the we need to ingress 
our database is need to be opne to the public request for that we need to crate one srvice 
ingress component is used for the route the trafic in to the cluster 

configmap-- is used for the external configuration for the application 
it conatins like URl of the application  

secreat--used for the store the secreat data credentail it wont store in the form plain text 
it will store in the form of (base64encoded)

deployment-- blue print for my-app pods  

statefulsets--deployment for stateless apps
statefulset for stateful apps or database replicating the pods and scaling them up and down
  
statefulsets--let take exampeof the my sql 
we created 3 sql pods fro each evevry pods we gaven static name and ip when that pod is die means 
ip and name wont be change that will keep connection to the msater node when we deplyed in the 
farm of statefulsets  
ex-- slave mechine details shoud be avilable in the master node 
in order to know which is master node for that slave mechine should have a ip adress of the 
master node ,when pod will die that time ip and host name will be changed on that that pod will
wont use so if deploy using this statefulsets means then it remains same .

 What is CRI in Kubernetes?
The CRI is a plugin interface which enables the kubelet to use a wide variety of container runtimes, 
without having a need to recompile the cluster components. You need a working container runtime on each Node in your cluster, 
so that the kubelet can launch Pods and their containers.


AWS_____
While login in as ubuntu instance it will as Loginas: (We need to provide=ubuntu)
                  Redhat instance it will as Loginas: (We need to provide=ec2-user)

 



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

pod-defination YML file

apiVersion:--This is the version of the k8s we are using the creating the object 

KIND           VERSION
POd               V1
Service           V1 
ReplicaSet       apps/V1
Deployment       apps/V1


kind: The kind refers to the type of object we are create
metadata:meta data is akind of the object like name and labeles   
 name:is a string value (we can name our pod and ) 
 labels:it is doctionary it is key value pair  
   apps:
spec: it is dictionaty we can under more containers 
containers: 
 - name: container name  
   image:image name



apiVersion: v1
kind: pod
metdata: 
  name: myapp-pod
  labels:
      app: myapp
      type: front-end
spec:
  containers: 
    - name: ngnix-container
      image: ngnix



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=

SDLC--Software Development life cycle 

1) Requriment Gathering-- collecting the requriment regading the project requriment form 
client (BRS--Business requriment specefication)

2)Analysis &Planning--here dicussion is held with the all the teams and business analysis will
explain the wats requriment for client they dicussed all the things and they prepared one dcoument 
called (FRS/SRS--Functional requriment specefication,system requriment specefication) 
like in that docuemt what kind od cloud  we need  what kind of functinalityesis requried what kind 
of sysyetm is reqiried what kind of licences is reqiried how many peoples is requried and also
time duration  
  
3)Design & Prototype-- development team are busines analysis team will design a blue print 
 it contais this ind of screens database structure will be luks like this they will create
one kind of rought work
 
4)Development--in this face developers and programers are ready for writing the code based 
on the requriment 

5)Testing--once build small portion is happen testers will test that that is working are not 
based Brs document the client reqiriment its happening the similtaniously 

6)Integration & Deployment-- After development is docne we need t o that in to live software 
clinet server 
 
7)Maintaince --- we need to provide security firewalls to safeing the app form hackers
in data base all the things are updated are not  will check user detai;s re updating are not 
checking the backups   

   
# git restore-- bring back to untracked section
# git log-- it  will store all comitted files 
# git rebase-- this is called fastforword branch (latest commits of the master)
the commits from the child  brnch are added to the top of the master branch 
# git check out--it is using for the shift to one branch to the another branch  
#merge-- merging the chlild branch in to master branch in linear passion s
# cherrypick--selectivily pickup the commiths form the child branch 
#git stash-hiding the files(or)storing the files 
git fetch--The git fetch command downloads commits, files, and refs from a remote repository into your local repo.
git commit--commits are simply that making changes in our prject 
git pull--dwonload the code into local repo from remote repo 
hotfix-* This is to deal with production issues where quick fixes are required. 
They can branch off from the master itself, but need to be merged to both master and develop branches.
git feature branch-* feature branches are used to develop new features and branches off exclusively from the develop branchgit 
git branch -d (branch name)-command for removing the branchesss
git brances are effectly pointer to snapshots our changes and independent line of development 
GIT-clone-> it will clone the what evevr we stored everything it will clone in the local
GIT-fetch r pull -->only updated content will get 

GITHUB--> git hub will refer the storing the source code 


Git Branching Strategies Explained
In any DevOps environment, version control is one of the primary components of the DevOps pipeline It effectively allows the
    Managing all the source code changes.

    Tracking all code changes.
    Enabling multiple developers to work on the same project simultaneously.
Simply put, a branching strategy is something a software development team uses when interacting with a 

version control system for writing and managing code. As the name suggests, 
the branching strategy focuses on how branches are used in the development process.

Blue green deployment-- it is devops release managment technique that reduses downtime  and code deployment risk 
to run test and provide reliable and zero downtime software upgrade 
the goal of blue green deployment is to achive immutibale infrastructure
*here we have two sets of deployment one is blue and green it means compltely maintaint two diffrent infrastructure for our application
 @ blue instance currently user are talking  

what is web server --web server are compouters which are delievery requested web pages 
every web server has ip adress and a domain name  

What are tags in Ansible?
A tag is an attribute that you can set to an Ansible structure (plays, roles, tasks),

Ways to Use Secrets in Ansible
To store secrets, credentials, certificates with Ansible, you have several possibilities.
 You can use Ansible Vault which allow to encrypt all your sensitive information


command for whan installing the package linux in between it stop due to the some issue 
so in the we need to use 
to update the brokage package in linux #apt-get --fixmissing ,apt install -f 
in order to know the maximumsize of the file # du -sh file name
if we dont know the file name #du -sh / , tree 
command for the sorting the file #sort

docker-->docker is virtulization platform that helps to user develop, deploy manage and run application docker container y
with all thir libraries and dependencies

docker container--> is a package wheare all the both dependencies the souce code all the libraries 

containerization-->nxt level of containerization 

docker networkig--> it is a idile sloution for to run application in all system 
docker network are used to provide complte isolation for docker container 
docker container is having thier own ??????????????????????????

About docker file
Docker file start with caps(D) this docker file is text file in this avalbale some instruction 
by using this we can create docker image and using this this image we can create a docker container
Instruction in docker file

Base image is need for the launch the intermediate conatiner during the launch the conatiner
during the building the conatiner we are using some commands like run build 
1) FROM--> using this we are creating the base image for ex let take (jenkins image)
2)WORKDIRECTOTY-->a directory contains a oter directory as well  
3)COPY-->It is used copying the files to the container during the build process
Imp--> While copying the files we are mentioning two dots (. .)
{1 dot is for build context (from) 2nd dot is destination(wheare)}
3)ADD-->add is also used to add the files to the container during the build process 
it will copy the jenkins file 
it will extract the file like archive files like tar.gz 
4)RUN-->is important Run is using the build process 
run command is used for 
*install an applications,
*compile&build
*publish the application in build container 
*test 
all thease can du while using the run instruction during the build
5)EXPOSE-->expose instructio is used to on which port our application is need to be exposed 
6)CMD-->Is used or the what command to launch your containe with 
7)ENV--> it used to define the enviroment varibales 
8)ENTRYPOINTS-->it could be a command are typicaly it is script that we want to launch 
when we initilization steps before launching the any application we can define usig the entry point  
  
docker advantages
#Rapid deployment 
#portablity
#Better effenciency
#faster configuration
#scablity
#security
 
docker--(sandbox)-->it is an isolated sandbox that holds the network configuration of container 

docker end points--> it establish connectivity for container service (within network) with other service

docker engine--> docker engine is base engine installed on your host machine to build and run container using 
docker components and service 
 
docker image-->it contains all the project code

using docker image any user can run the code and in order to create docker container 

For removing the all containers--> #docker container prune 

default network mode of docker--Bridge mode
docker networks are-->Bridge,Host,None

Dokcer CMD --> when ever we used CMD in docker file it will execute only when the command is in CMD 
if supose if we passed any arguments means that arguments will rplace with CMD command 
if we want to exucute that as it is entire command we need to write in a command prompt when container creating  

Docker ENTRYPOINT-->In entry point the value is present in that it will exucute the same value 
if we pass any arguments it will apend to that entry point 

Docker ENTRYPOINTs
In Dockerfiles, an ENTRYPOINT instruction is used to set executables that will 
always run when the container is initiated. Unlike CMD commands, 
ENTRYPOINT commands cannot be ignored or overridden—even when the container runs with command line arguments stated

Dokder CMD--> In docker cmd shell script is embaded it is shell that litennainout form a terminial 
if it cannot find terminal it exects 

What are the three main Docker components?

    Docker Client. Docker client uses commands and REST APIs to communicate with the Docker Daemon (Server). ...
    Docker Host. ...
    Docker Registry. 

How do I open a Docker container?
docker exec -it <container_id>

Docker compose
This is a feature of docker using which we can create multicontainer architecture using yaml files

Docker volumes
Generally, when a container is deleted all its data will be lost.
To preserve the data, even after deleting the container, we use volumes.

To execute anycommand in a container 
   #docker exec -it container_name/container_id command
   Eg: To launch the bash shell in a contianer 
   #docker exec -it container_name/container_id    bash 

creating the containers in windows 
1) we need ti pull the images 
# docker pull (image name)
2)now create a conatiner (when we run the inage container gets created)
docker run it -d (container_name)
3) for checking it installed or not 
# docker ps -a
3) inorder to acessing the running container 
# docker exec -it (container id) bash 
4)in order to create a new image inside the container 
#docker commit (container id) rahu/ubunt 
(rahul is name of the git hub)

How to create image by using the docker file?
1) First we need to create docker file '
2) Move to the 

Docker volumes++++++++
Generally, when a container is deleted all its data will be lost.
To preserve the data, even after deleting the container, we use volumes.
If we attach the vlome  to the container if container will dlete means means using that mount path we can get back data from in it 
while we attaching volume to the container mount path is created

how to start srvice with docker compose??

resource can I use to schedule 1 pod per node? Pod should also be available on new nodes if added in future ?
DaemonSet

entering in to the container #docker exec -it <container_name>

Docker Compose-->This feature of docker using wich we can create a multiple container archicture using yaml files 
 
How to convert a docker container in to image
# docker commit c11 demobox
c11--> it stands for alreday created container name 
demobox--> it is for giving new image name 



s3 is object storage

Public IP will get changed if the instance is stopped and started again. On the other hand, Elastic IP is static

A public IP can reach the internet directly. A private IP needs a NAT gateway to reach the internet.

NAT Gateway is a highly available AWS managed service that makes it easy to connect to the Internet from instances within a private subnet

The advantage of an Elastic IP  is that you can move an IP address from one host to another.
This can help you to build a more resilient system.

What are the types of controllers in Kubernetes?
Examples of controllers that ship with Kubernetes today are the replication controller, endpoints controller, namespace controller, and serviceaccounts controller.04-May-2022


why we need to use aws means
for # Avilabilty 
    # Scaliablity 
    # Pay as u go

what is web server
Aweb servevr is program that run on the particular ec2 mechine it will accept the patricular incomimg request
when ever we are acessing the particulr application form the web serevr web server ishaving web pages it providea web pages as our request 
webserver is program it will accept the request  as a response to the request it delivery web pages  
examples
*Apache HTTP server
*Internet Information service
*ngnix
*http by apache 

incident management is nothing but a ticketig tool 
incident is something that techinically takes care the process of help desk 
service now is a software platform that supports IT  service managment and automates common business process

Load balancer is distributing the load and monitoring the health of the targets 

what is bootstrap script--> set of command that are excuted automatcally when the mechine start automatically 
in aws while creating the servevr we can do this in configure tab @ user data 

 how does the load balance knows ec2 server is workign are not 
load balancer is sending the ping request to the ec2 sever if ir respaose then only load balance knows it is helathy

VPC-virtual private coud (virtual data center in the cloud) (Isolated cloud resourcess)
it means we are creating our own cloud in virtual 
first we need to create a partation in that we can crate ec2 and what ever we want 
when customer needs a aws data center we ned to create a first step is VPC...

Horizontal scaling-OUT-->creatitng the more instancess when load is more 
Horizontal saling-IN-->Decreasing the instance when load is less
Vertical scaling-OUT-->Increasing the ram and cpu more
Vertical scalong-IN-->Decreasing the ram and cpu 

if the subnet mask is less then we create more server , if subnent mask is more then servevrs wil be decrease 

subnets values calucations
max subnent mask range is 32 and list is 16 

32
16
-------
-16

2 power of 16 =65536
so we can create in 65536 server in vpc

ip range is 0-256

diffrent types of serverrs 
*Webserver
*Application server
*Datat base servevr

we can't dup all the severs in vpc for that we ned to crate a sunet
subnet-- subnet is a partion done inside the vp 
Default behaviour of the subent is PRIVATE

web server -- we want everyone in the world to acess web server
always request will be sent to web server 
from web server request will be sent to data base server

How to make subnet public
by creating the IGW attaching to the vpc 

IGW-->Internent gate way component is used to provide a internent connecctivity to he subnet 
(we need to conent the that to VPC)

one vpc should have one internent gate way 

we cant connet IGW directly to the subnet it is not possible so for that we need to create a Route table(RT)

Route tables--> it is mediator between the IGw and subnent 
one end of the route table we nned to conne to the IGW one end of the rote table we neee to connect ot the subnet 
route table will helps to the conneting the IGW and Subnet

steps to make subnent public 

we need enable Ip adressof the subnent-->create a IGW--->Route Table
                                                         (conneting for subnent) go to action-->their we can avliable subnets selet that-->save it... 

                                                         (connecting for IGW) go to action-->Edot Routes-->Destination(0.0.0.0/0),Target (IGW)-->save changes..

in order to create DB instance in DB subnet we need to open the for WEB srvevr need to be communicate wit DB sever
we ned to be open port is MYSQL/Aurora port 

NAT_gate way (Network adress Translator)-->it provide internent to private subnet 
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Platform	                                       Examples
PaaS-->(platform as service)	                       AWS Elastic Beanstalk, Google App Engine, and Magento Commerce
SaaS-->(software as a service)	                       Gmail, Slack, and Microsoft Office 365
IaaS-->(Infrastructure as a service)	               Amazon Web Services, Microsoft Azure, and Google Compute Engine
IAAC-->( Infrastructure As A Code)                     AWS CloudFormation, Red Hat Ansible, Chef, Puppet, SaltStack and HashiCorp Terraform.


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Web servevr are the compouters that delivey the requested web pages.every web pages has thier own IP adress and Domain name 

NGINX--->
Using this nginx server we are hiding the target servers ips and all the information only we are giving the nginx ip adress 
for enduser in order acess the serverv 
nginx is basically web server by which sure that web page time load is redused 
 Reverse proxy is a open software webserver for reverse proxying cashing and load balancing 
it designed for maximum performance and stablity 

Basically any compouter became  weserverv  we need to install some softwares and connect the mechine to the internet 
which is basically global area network If we want to make our web server we need to intall apps like ngnix 
s
nginx usess master-slave architecture by supporting event-drive, asynchronous and non-blocking model 

Load balancing is a process that distribut the load to the various resourcess  

PROXY SERVER++++++++++
proxy server helps to security of the clients mechines..

Firewall-->proxy is act as shiled , filter and firewalls  between the inranet and internet and it fileters the all bad stuf from the internet 

Better managment-->the proxy servers are which manage the all the client severs request at one place and pass it out side to internet 
better managment of all our client mechine while taking data form the internet 

cashing--> if same time all the client mechines requested one static content first proxy server it takesfrom internent and it will store as 
cashe data and again requtesd comes from the client mechine it can privide easily witout approaching the agin to internent 

Encription-->encripting the ip adress of the client mechine if any request comes from the client mechine proxy server will hide encript the information of the client 
mechine so  that internet does know wheare the request comes form 

REVERSE PROXY++++++++
Reverse proxy server can acts as load balancer 
Reverse proxy is all about same as like proxy but if request comes from internet which want to acess any of the client servers with in the network 
insted of exposing client servers it has to goes to reverse proxy then reverse prixy desides how to filter tht reuest and send it forword 
Load balancing--> Reverse proxy heplps the balance the load  it acts as load balancer between the internent and servers 
it will helps the compress the request size which to increase the over all bandwidth of the performance 


storage types+++++++++
Creating a volumes and using the snapshot in aws we can take a backup of the data form one region to another region 
vloumes are addatinal storage attaching to the servers 


Block store-> this block storage store the data in equaliy distribted blocks 
when we updating a block store that will not update entire file it is update a a piece of block
os are  booted onfigure with block storage ex: like our system are laptop 
(EBS-Elastic block storage) we need to mount the server then only we can read the server
storage capacity of EBS- 16TB 


File store-->
The file are datat will be maintained hirachical format
EFS-Elastic file syatem  

Object store-->each and every object (file/data) which is uploaded to object store will have unique object id and end point 
s3-simple storage ex(google drive are one drive) we dont need to mount we can acess the data from anywhare 

we cant attach multiple elastic ips for multiple servers 

Three tier Archicture
Web_server--> 
All the fron_end stuff is taken by Web_server
web server is neede for the extending the application if want o tadd some business logic 
some UI stuff login funcationality and more

Application server--> 
it all kind of business application in order to connect with diffrent people addin the data everything is 
taken by application_server

Database_server-->
if want to extend our application we need DB server 
s
DB_Cache engine--> we can quary the frequently acess data the application server  docnt hit the data base
but all the request serverd form the DB_cache 

duf: Check free drive space from the terminal

Frame work-->
frame work provide a basic structure to our application and tools helps develop the application 

spring boot 
spring boot application will gives production ready application 
if we have server we need to install Linux server like #hardware-->os(linux)-->web_server or app_server(tomcat)
for deploy application we need all but when we choose spring it will give all dependencies  
it provided a embaded software that isjar files and war files inside that tomcat it will give it is called embaded software 
spring boot application contains a (application.properties) if we want to do any configuration we need to use this 


what is the diffrence between HTTP and SSH
HTTP--> if we gave HTTP security group that can sevevr can acess world wide
SSH-->ifwe gave SSH means only known peoples can get acess to the that sevevr 

A Maven phase represents a stage in the Maven build lifecycle.

#validate: check if all information necessary for the build is available.
complie is nothing but a converting the source code Byte code (byte code-->mechine langauage)
Byte code is having alphabets only (ABCD)
#test-compile: compile the test source code.
#test: run unit tests.
#package: package compiled source code into the distributable format (jar, war, …)
# Install: Iy will store build artifact in to maven local repo s
#Deploy: It will store the Build Artifat in Remote Repo 
#clean: It Deletes the previous history 
#It will create the documentation for java source code 


bin: It contains Binary Files
  the fiels are
 *sh startup.sh 
 *startup.bat
          (bat.--> Batch files)
conf:
    Configuratin files it contain 
    #server.xml
    #tomcat-user.xml
lib:
    It contains a (jar)files
logs:
   It conatains a tomcat log files
    *catlina.out
    *local Host
    *Manager log
    *hostmanager log

Tomcat-Web Apllication server it support (WAR-files)
JBOSS- It is a enterprise app server it support (WAR and EAR)files
 
What URI means->Uniform Resource Identifier
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=

PYTHON.....>>

Python is the one of the High level programing lauangauge 

Libraries--> is nothing but a free defined set of code 
program--> set of instruction is  call it has program

diffrence between interpretand compailer 
Interpreter--> line by line exuction (if error occured stop the execution)
Compailer-->It will scan the entire program and it will dispaly if anything is worng erorr ata time 

Three types of Lanagauges 
1)Mechine level launagaes---> compouter 0,1
2)Assembly lauanagauge-->
3)High level lauanagauge-->English statements(C,C++,Java,Python)
                             
What these Interpretr and compailer will do means it will conver High level program to low level program  

What is Bootstrap-->Bootstrap is a potent front-end framework used to create modern websites and web apps. 
It's open-source and free to use, yet features numerous HTML and CSS templates for 
UI interface elements such as buttons and forms. 
Bootstrap also supports JavaScript extensions.

Variables++++++++
reusablity od the values 
The value if we want use multiple times so that we can go with variables
Ram is allocated some memory for the varibales 
we can assign a value to the variables and wheare it requried we can use it 
Idenfiers--> Names are variable are functions, classes 
ex:-
id = 101 
name = rahul 

The value Assigned to the variable we can use it again when ever we want 
ex:-
a = 128
b = 150 
Insted of using the value again and again 
The vaule is assing to the varaibles (That data is stored in the a&b) when evevr we wan twe can use the varibales 

Python is Multiparadisim (It has taken all the features of diffrent langauges )
                                   Produceadural/ functional --> C
                                   Object oriented--> Java 
                                   Bash-script

Identfier is start with (A-Z a-z or _hypen)

Redis is a end memorystorage memory component it basically use as data base 

Datatypes
Datatypes referesents type of the data
1)Built in Datatypes
2)User defined data type









how to install .sh filein ubuntu/linux machine
# chmod +X install.sh
it will crete a excutable file
now install
sudo ./install.sh
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
ARFICACRORY TOOL-->Nexuss

Whtat is the diffrence between git hub and nexuss
we can store war and jar files in the git hub but we cant get specefic file from the fi


inorder to view the (.file) on windows
press shift and . 

Higher level-->lauanaguage means it is clsose to english like only human can understand
Lower lauangauge-->it means that it is close to 0101 byte code for electronic lanagauge only mechine can understand 

pytho usally used interprttter to code converting 
Interpretter--> is go by line line by line for excution
compiler --> it will take all the code and it will conevert in to mechine lanagauge  


(Nexuses)Artifactory repository--> once code is build  artifactiry is reday before deploying if we need one more copy menas we are storing that in to the arfifact 





















